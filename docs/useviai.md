# Using the solution

At this point, your ML model is deployed at the edge server. You can use the solution in different ways.

The following sections show different scenarios of use:

 * [Local inference with images from a camera](./usinglocalinference.md)
 * [Streaming inference results to BigQuery](./usingbigquery.md)
 * [Streaming inference results to local MQTT for local actions](./usingmqtt.md)
 * [Launching physical actions based on inference results](./usingphysicalactions.md)
 * [Triggering inspection remotely with an MQTT command](./usingtriggerinspection.md)
 * [Using multiple cameras, with dedicated ML models, triggered simultaneously](./usingmultiplecameras.md)
 * [Batch processing inference against a set of image files](./usingbatchprocessing.md)

<br>

The following sections give you more information about the VIAI Edge app and how to use it:

 * [Using a camera and the VIAI model container without the camera client application](./misccameranoclient.md)
 * [Logging and debugging](./misclogging.md)
 * [Camera connection health checks](./misccamerahelthcheck.md)
 * [Automatic deployment options](./miscautomaticdeployment.md)
 * [Improving GPU utilization in Kubernetes](./miscimprovegpuuse.md)

<br>
Troubleshooting sections for the most common issues:

 * [Generate inspection reports](./troubleshootingreports.md)
 * [Troubleshooting cloud resources provisioning](./troubleshootingcloudresources.md)
 * [Troubleshooting Anthos Baremetal installation](./troubleshootingabm.md)
 * [Troubleshooting Anthos config sync](./troubleshootinganthosconfig.md)
 * [Troubleshooting camera integration container](./troubleshootingcameraintegration.md)
 * [Troubleshooting NVIDIA GPU](./troubleshootingnvidia.md)


<br>
Cleanup after testing the solution:

 * [Cleaning up Google Cloud resources](./cleanup.md)
